{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import iss_preprocess as iss\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mask dfs from each tile\n",
    "data_path = \"becalia_rabies_barseq/BRAC8498.3e/chamber_08/\"\n",
    "processed_path = iss.io.get_processed_path(data_path)\n",
    "prefix = \"mCherry_1\"\n",
    "ops = iss.io.load_ops(data_path)\n",
    "df_dir = processed_path / \"cells\" / f\"{prefix}_cells\"\n",
    "df_files = glob.glob(str(df_dir / \"*.pkl\"))\n",
    "dfs = [pd.read_pickle(f) for f in df_files]\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reference tile no filtering\n",
    "ops = iss.io.load_ops(data_path)\n",
    "suffix=ops['mcherry_projection']\n",
    "background_ch=ops['mcherry_background_channel']\n",
    "signal_ch=ops['mcherry_signal_channel']\n",
    "  \n",
    "print(ops[\"mcherry_ref_tile\"])\n",
    "from iss_preprocess.pipeline import load_and_register_tile\n",
    "(roi, tilex, tiley) = ops[\"mcherry_ref_tile\"]\n",
    "stack, _ = load_and_register_tile(\n",
    "    data_path, tile_coors=(roi, tilex, tiley), prefix=prefix, filter_r=False,\n",
    "    projection=suffix\n",
    ")\n",
    "stack = stack[...,0]\n",
    "plt.title(\"Reference tile raw mCherry channel\")\n",
    "plt.imshow(stack[:,:,signal_ch], vmax=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "processed_path = iss.io.get_processed_path(data_path)\n",
    "background_image = stack[:, :, background_ch]\n",
    "mixed_signal_image = stack[:, :, signal_ch]\n",
    "\n",
    "# Flatten to 1D arrays for the regression model\n",
    "background_flat = background_image.ravel()\n",
    "mixed_signal_flat = mixed_signal_image.ravel()\n",
    "\n",
    "ops = iss.io.load_ops(data_path)\n",
    "background_coef = ops[\"background_coef\"]\n",
    "threshold_background = ops[\"threshold_background\"]\n",
    "\n",
    "# Remove pixels that are too dark or too bright\n",
    "bright_pixels = (\n",
    "    (background_flat > threshold_background) & (background_flat < 4090)\n",
    ") & ((mixed_signal_flat > threshold_background) & (mixed_signal_flat < 4090))\n",
    "background_flat = background_flat[bright_pixels].reshape(-1, 1)\n",
    "mixed_signal_flat = mixed_signal_flat[bright_pixels]\n",
    "\n",
    "# Initialize and fit Linear model\n",
    "model = LinearRegression(positive=True)\n",
    "try:\n",
    "    model.fit(background_flat, mixed_signal_flat)\n",
    "    # Predict the background component in the mixed signal image\n",
    "    predicted_background_flat = model.predict(\n",
    "        background_image.ravel().reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    predicted_background = predicted_background_flat.reshape(background_image.shape)\n",
    "\n",
    "    # Subtract the predicted background from the mixed signal to get the signal image\n",
    "    signal_image = mixed_signal_image - (\n",
    "        predicted_background * background_coef\n",
    "    )  # TODO: Remove fudge factor\n",
    "    signal_image = np.clip(signal_image, 0, None)\n",
    "    print(\n",
    "        f\"Image unmixed with coefficient: {model.coef_[0]}, intercept: {model.intercept_}\"\n",
    "    )\n",
    "except ValueError:\n",
    "    raise ValueError(\"Not enough data passing background threshold to fit model\")\n",
    "\n",
    "coef = model.coef_[0]\n",
    "intercept = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot linear regression\n",
    "plt.figure()\n",
    "plt.scatter(background_flat, mixed_signal_flat, s=1)\n",
    "plt.plot(background_flat, model.predict(background_flat), color=\"red\")\n",
    "plt.xlabel(\"Background\")\n",
    "plt.ylabel(\"Signal\")\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.text(\n",
    "    0.5,\n",
    "    0.9,\n",
    "    f\"y = {coef:.2f}x + {intercept:.2f}\",\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\",\n",
    "    transform=plt.gca().transAxes,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = iss.vis.to_rgb(np.dstack([mixed_signal_image, background_image, signal_image]), colors=[(1, 0, 0), (0, 0, 1), (0, 1, 0)], vmax=[200,200,100])\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(rgb)\n",
    "plt.axis(\"off\")\n",
    "for i in range(3):\n",
    "    valid_img = np.zeros_like(rgb)\n",
    "    valid_img[:,:,i] = rgb[:,:,i]\n",
    "    ax = plt.subplot(2,2,i+2)\n",
    "    ax.imshow(valid_img)\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "print(\"Red: mCherry signal, Blue: Background, Green: Unmixed signal\")\n",
    "for x in fig.axes:\n",
    "    x.set_xlim(1500, 2500)\n",
    "    x.set_ylim(800, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_triangle\n",
    "plt.figure(dpi=300)\n",
    "fig, ax = plt.subplots(1,2, dpi=300)\n",
    "ax[0].imshow(signal_image, vmax=300)\n",
    "ax[0].set_title(\"Signal Image\")\n",
    "#make signal image have extra dimension\n",
    "signal = signal_image[:, :, np.newaxis]\n",
    "filt = iss.image.filter_stack(\n",
    "    signal, r1=ops[\"mcherry_r1\"], r2=ops[\"mcherry_r2\"], dtype=float\n",
    ")\n",
    "binary = (filt > threshold_triangle(filt))[:, :, 0]\n",
    "ax[1].set_title(\"Binary Image\")\n",
    "ax[1].imshow(binary)\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "    a.set_xlim(1500, 2500)\n",
    "    a.set_ylim(800, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering masks\n",
    "\n",
    "After the initial detection, we filter things taht are not cells.\n",
    "Here is what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi, tilex, tiley = 5, 2, 4\n",
    "fmasks, filtered_df, rejected_masks = iss.pipeline.segment.segment_mcherry_tile(data_path,\n",
    "    'mCherry_1',\n",
    "    roi,\n",
    "    tilex,\n",
    "    tiley,\n",
    "    filter_masks=True,\n",
    ")\n",
    "\n",
    "masks, filtered_df, rejected_masks = iss.pipeline.segment.segment_mcherry_tile(data_path,\n",
    "    'mCherry_1',\n",
    "    roi,\n",
    "    tilex,\n",
    "    tiley,\n",
    "    filter_masks=False,\n",
    ")\n",
    "unmixed_image, mixed_stack = iss.pipeline.segment.unmix_tile(data_path, 'mCherry_1', (roi, tilex, tiley))\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(masks)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(fmasks)\n",
    "plt.subplot(2, 2, 3)\n",
    "rgb = iss.vis.to_rgb(mixed_stack, colors=[(1,0,0), (0,1,0)], vmax=[200,200])\n",
    "plt.imshow(rgb)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(unmixed_image, vmax=200, cmap='inferno')\n",
    "for x in plt.gcf().axes:\n",
    "    x.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "mixed_stack = np.dstack([signal_image, background_image])\n",
    "labeled_image = measure.label(binary)\n",
    "props = measure.regionprops_table(\n",
    "    labeled_image,\n",
    "    intensity_image=mixed_stack,\n",
    "    properties=(\n",
    "        \"label\",\n",
    "        \"area\",\n",
    "        \"centroid\",\n",
    "        \"eccentricity\",\n",
    "        \"major_axis_length\",\n",
    "        \"minor_axis_length\",\n",
    "        \"intensity_max\",\n",
    "        \"intensity_mean\",\n",
    "        \"intensity_min\",\n",
    "        \"perimeter\",\n",
    "        \"solidity\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "props_df = pd.DataFrame(props)\n",
    "props_df[\"circularity\"] = (\n",
    "    4 * np.pi * props_df[\"area\"] / (props_df[\"perimeter\"] ** 2)\n",
    ")\n",
    "# unmixed_image has two channels, signal and background\n",
    "props_df[\"intensity_ratio\"] = (\n",
    "    props_df[\"intensity_mean-0\"] / props_df[\"intensity_mean-1\"]\n",
    ")\n",
    "plt.imshow(labeled_image%20, cmap=\"tab20\", interpolation=\"none\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_thresholds = dict(area=200) #,solidity=0.9, )\n",
    "max_thresholds = dict()#solidity=1)#, area=5000, eccentricity=0.99)\n",
    "max_thresholds['intensity_mean-1'] = 200\n",
    "\n",
    "fig, axes = plt.subplots(3, len(min_thresholds) + len(max_thresholds), figsize=(20, 15))\n",
    "for icol, (prop, val) in enumerate(min_thresholds.items()):\n",
    "    unvalid = props_df[prop] <= val\n",
    "    valid_img = np.empty(labeled_image.shape) + np.nan\n",
    "    rejected_img = np.empty(labeled_image.shape) + np.nan\n",
    "    img_lvl = np.empty(labeled_image.shape) + np.nan\n",
    "    for index, unvalid in unvalid.items():\n",
    "        label = props_df.loc[index].label\n",
    "        if unvalid:\n",
    "            rejected_img[labeled_image == label] = label           \n",
    "        else:\n",
    "            valid_img[labeled_image == label] = label\n",
    "\n",
    "        img_lvl[labeled_image==label] = props_df.loc[index][prop]\n",
    "    axes[0, icol].imshow(valid_img%20, cmap=\"tab20\", interpolation=\"none\")\n",
    "    axes[0, icol].set_title(f\"{prop} > {val}\")\n",
    "    axes[1, icol].imshow(rejected_img%20, cmap=\"tab20\", interpolation=\"none\")\n",
    "    axes[1, icol].set_title(f\"{prop} <= {val}\")\n",
    "    im = axes[2, icol].imshow(img_lvl, cmap=\"viridis\", vmax=min(val, img_lvl.max()), interpolation=\"none\")\n",
    "    cb = plt.colorbar(im, ax=axes[2, icol])\n",
    "    axes[2, icol].set_title(f\"{prop}\")\n",
    "for icol, (prop, val) in enumerate(max_thresholds.items()):\n",
    "    unvalid = props_df[prop] >= val\n",
    "    icol += len(min_thresholds)\n",
    "    valid_img = np.empty(labeled_image.shape) + np.nan\n",
    "    rejected_img = np.empty(labeled_image.shape) + np.nan\n",
    "    img_lvl = np.empty(labeled_image.shape) + np.nan\n",
    "    for index, unvalid in unvalid.items():\n",
    "        label = props_df.loc[index].label\n",
    "        if unvalid:\n",
    "            rejected_img[labeled_image == label] = label           \n",
    "        else:\n",
    "            valid_img[labeled_image == label] = label\n",
    "\n",
    "        img_lvl[labeled_image==label] = props_df.loc[index][prop]\n",
    "    axes[0, icol].imshow(valid_img%20, cmap=\"tab20\", interpolation=\"none\")\n",
    "    axes[0, icol].set_title(f\"{prop} > {val}\")\n",
    "    axes[1, icol].imshow(rejected_img%20, cmap=\"tab20\", interpolation=\"none\")\n",
    "    axes[1, icol].set_title(f\"{prop} <= {val}\")\n",
    "    im = axes[2, icol].imshow(img_lvl, cmap=\"viridis\", vmax=min(val, img_lvl.max()), interpolation=\"none\")\n",
    "    cb = plt.colorbar(im, ax=axes[2, icol])\n",
    "    axes[2, icol].set_title(f\"{prop}\")\n",
    "\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Valid\")\n",
    "axes[1, 0].set_ylabel(\"Rejected\")\n",
    "for x in axes.ravel():\n",
    "    x.set_xticks([])\n",
    "    x.set_yticks([])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh = df[df[\"area\"] > 600]\n",
    "df_thresh = df_thresh[df_thresh[\"area\"] < 5000]\n",
    "#df_thresh = df_thresh[df_thresh[\"circularity\"] <= 1]\n",
    "#df_thresh = df_thresh[df_thresh[\"circularity\"] >= 0.7]\n",
    "df_thresh = df_thresh[df_thresh[\"solidity\"] >= 0.9]\n",
    "df_thresh = df_thresh[df_thresh[\"solidity\"] < 1]\n",
    "df_thresh = df_thresh[df_thresh[\"eccentricity\"] <= 0.99]\n",
    "df_thresh = df_thresh[df_thresh[\"intensity_mean-1\"] < 200]\n",
    "features = ['area', 'circularity', 'solidity', 'intensity_mean-1', 'intensity_mean-0'] #,'solidity' 'major_axis_length', 'minor_axis_length' #  'solidity', 'intensity_mean-1', 'intensity_mean-0' ,'eccentricity',\n",
    "df_thresh_norm = (df_thresh[features] - df_thresh[features].min()) / (df_thresh[features].max() - df_thresh[features].min())\n",
    "scaled_features = scaler.fit_transform(df_thresh_norm[features])\n",
    "df_scaled_features = pd.DataFrame(scaled_features, columns=features)\n",
    "df_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_scaled = np.array(\n",
    "    [\n",
    "        [-0.81560289, -1.16570977, -1.16885992, 0.68591332, -0.47768646],\n",
    "        [-0.08201876, 0.48188625, 0.38447341, -0.41695244, -0.42873761],\n",
    "        [0.97601349, 0.61105821, 0.74187513, -0.18499336, 1.06977134],\n",
    "    ]\n",
    ")\n",
    "n_components = 3  # for good masks vs debris, adjust as necessary\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=n_components, \n",
    "                      #init_params='kmeans',  # default, consider 'random' if k-means doesn't work well\n",
    "                      means_init=cluster_centers_scaled,  # optional, if you have strong priors about cluster centers\n",
    "                      random_state=42,\n",
    "                      verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "gmm.fit(df_scaled_features[features])\n",
    "\n",
    "# Predict the cluster labels\n",
    "labels = gmm.predict(df_scaled_features[features])\n",
    "\n",
    "cluster_centers_scaled = gmm.means_\n",
    "\n",
    "# Inverse transform the scaled cluster centers\n",
    "cluster_centers_norm = scaler.inverse_transform(cluster_centers_scaled)\n",
    "\n",
    "# Rescale normalized cluster centers to original scale\n",
    "min_values = df_thresh[features].min().values\n",
    "max_values = df_thresh[features].max().values\n",
    "\n",
    "# Rescale normalized cluster centers to original scale\n",
    "cluster_centers = cluster_centers_norm * (max_values - min_values) + min_values\n",
    "\n",
    "df_thresh['cluster_label'] = labels + 1\n",
    "image_df = df_thresh[(df_thresh[\"roi\"] == roi) & (df_thresh[\"tilex\"] == tilex) & (df_thresh[\"tiley\"] == tiley)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "pairplot_fig = sns.pairplot(df_thresh[[        \n",
    "        'area', 'circularity', 'solidity', 'intensity_mean-1', 'intensity_mean-0']], #'area', 'circularity', 'eccentricity','intensity_ratio', 'solidity', 'major_axis_length', 'minor_axis_length', 'intensity_mean-1'\n",
    "        diag_kind=None,\n",
    "        plot_kws={\"s\": 5, \"alpha\": 0.3, \"c\":labels, \"cmap\": \"tab10\"},\n",
    ")\n",
    "\n",
    "#overlay the cluster centers on the pairplot\n",
    "axes = pairplot_fig.axes\n",
    "feature_names = ['area', 'circularity', 'solidity', 'intensity_mean-1', 'intensity_mean-0']\n",
    "for i, feature_i in enumerate(feature_names):\n",
    "    for j, feature_j in enumerate(feature_names):\n",
    "        #if i != j:\n",
    "            # Only plot on the off-diagonal plots\n",
    "        for center in cluster_centers:\n",
    "                axes[i, j].scatter(center[j], center[i], c='red', s=50)  # color and size of the cluster center points\n",
    "\n",
    "\n",
    "# Now supress FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks = np.load(df_dir / f\"mCherry_1_masks_{roi}_{tilex}_{tiley}.npy\", allow_pickle=True)\n",
    "cell_masks = np.load(df_dir / f\"mCherry_1_cell_masks_{roi}_{tilex}_{tiley}.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "fig, ax = plt.subplots(1,2, dpi=300)\n",
    "ax[0].set_title(\"All masks\")\n",
    "ax[0].imshow(binary)\n",
    "\n",
    "ax[1].set_title(\"Cell masks\")\n",
    "ax[1].imshow(cell_masks, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
