{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register to ARA\n",
    "\n",
    "The aim is to register individual slices to the Allen Reference Atlas. Example solutions\n",
    "for this type of registration are described here:\n",
    "https://forum.image.sc/t/comparison-of-some-tools-for-brain-slice-to-atlas-registration/43260\n",
    "\n",
    "We will start with ABBA. This require a stitched overview in a pyramidal format. \n",
    "We start by generating that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from flexiznam.config import PARAMETERS\n",
    "import iss_preprocess as iss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define experiment to analysis\n",
    "project = \"becalia_rabies_barseq\"\n",
    "mouse = \"BRAC8501.6a\"\n",
    "chamber = \"chamber_08\"\n",
    "ref_acq = \"genes_round_4_1\"\n",
    "data_path = \"/\".join([project, mouse, chamber])\n",
    "processed_path = iss.io.get_processed_path(data_path)\n",
    "registration_folder = processed_path / \"register_to_ara\"\n",
    "registration_folder.mkdir(exist_ok=True)\n",
    "print(f\"Doing registration for {data_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitch tiles\n",
    "\n",
    "We will take all rois and stitch the `ops['ref_ch']` of  `reference_prefix` . The saved image are in the `register_to_ara` subfolder with a yaml for each to specify downsampling info. \n",
    "\n",
    "The same function will also generate two empty directories (if they don't exists yet): \n",
    "- `qupath_project`: to create and store a QuPath project needed to load data into ABBA\n",
    "- `deepslice`: to store small downsampled images uploaded to deepslice webpage and the `results.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = iss.io.get_pixel_size(data_path, ref_acq)\n",
    "pixel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug purpose\n",
    "if False:\n",
    "    iss.pipeline.ara_registration.overview_single_roi(\n",
    "        data_path,\n",
    "        prefix=\"genes_round_4_1\",\n",
    "        roi=5,\n",
    "        slice_id=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long step, generates all ome.tiff\n",
    "# (16 minutes for 1 ch of the infamous chamber_13, maybe an hour for 4 channels\n",
    "# with gaussian blur)\n",
    "if True:\n",
    "    prefix = \"genes_round_4_1\"\n",
    "    iss.pipeline.register_within_acquisition(\n",
    "        data_path, prefix=prefix, reload=True, save_plot=True\n",
    "    )\n",
    "\n",
    "    # for sigma blur, we use about 2um of pixels\n",
    "    sigma_blur = 1  # 2.0 / pixel_size\n",
    "    thumb = iss.pipeline.overview_for_ara_registration(\n",
    "        data_path=data_path,\n",
    "        prefix=prefix,\n",
    "        sigma_blur=sigma_blur,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ABBA\n",
    "\n",
    "The simplest is to do it from the virtual machine. See #ito-proj-znamenskiy-gpu-vm on\n",
    "slack for connection information.\n",
    "\n",
    "\n",
    "## Create a QuPath project\n",
    "\n",
    "- Once logged in, start QuPath, open the `register_to_ara` folder in windows file explore and drag&Drop the `qupath_abba` folder in QuPath.\n",
    "- Click Ok to create a new project\n",
    "- Drag&Drop the `ome.tif` files that you want to use for registration\n",
    "- Set Image Provider to \"Bio-Formats builder\", Set image type to \"Fluorescence\" and make sure that the tick box are unticked. Then import.\n",
    "- Delete the image #2, these are the thumbnails and we don't need them. (select them, right click, remove image, delete associated data)\n",
    "- Save the project and close QuPath\n",
    "\n",
    "\n",
    "## Load into ABBA\n",
    "\n",
    "- Start Fiji\n",
    "- Type `ABBA` in the quick search bar and select `ABBA - ABBA Start`\n",
    "- Select Allen Brain Atlas V3\n",
    "- For saving disk space you can use the same folder for brain map data: `file:/C:/abba_atlases/mouse_brain_ccfv3.xml` and ontology data: `file:/C:/abba_atlases/1.json`\n",
    "- Slicing coronal, BA: allen, then wait a bit.\n",
    "- In `ABBA`, click Import > ABBA - Import QuPath Project. You can keep the default import settings\n",
    "- Select the `project.qpproj` in `qupath_project`\n",
    "- Set the initial axis position. V1 is around 9mm\n",
    "- Set the slice spacing (usually 0.016mm if you slice front to back, -0.016 if you go the other way round)\n",
    "- Look at https://biop.github.io/ijp-imagetoatlas/ for navigation/display info\n",
    "\n",
    "##Â Register with DeepSlice\n",
    "See: https://biop.github.io/ijp-imagetoatlas/registration_with_deepslice.html\n",
    "\n",
    "- In ABBA, select all slices and select Align > DeepSlice (web)\n",
    "- Select the deepslice folder to save downsample data and tick everything\n",
    "- Wait, it takes time to downsample.\n",
    "- Follow the prompt\n",
    "- On the deepslice web page, tick everything\n",
    "- Save the results.xml in the same deepslice folder\n",
    "\n",
    "## Elastix\n",
    "\n",
    "- In ABBA select all the slices\n",
    "- In ABBA do first an affine transform\n",
    "- Still in ABBA do the Elastix non rigid transform\n",
    "\n",
    "## [Optional] Adjust manually\n",
    "\n",
    "You can select bigwarp to adjust the registration \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate coordinate images\n",
    "\n",
    "\n",
    "To get the output, which is an image with 3 channels for the x,y and z coordinates of each\n",
    "pixel in the ARA, click on export -> Image coordinates to imagej or something like that.\n",
    "\n",
    "This will open a bunch of windows. Save them all in the `ara_coordinates` subfolder. To \n",
    "make that painless you can use the following imagej macro:\n",
    "\n",
    "```\n",
    "dir = getDirectory(\"Choose a Directory\");\n",
    "//ids=newArray(nImages);\n",
    "for (i=0;i<nImages;i++) {\n",
    "        selectImage(i+1);\n",
    "        title = getTitle;\n",
    "        print(title);\n",
    "        //ids[i]=getImageID;\n",
    "\n",
    "        saveAs(\"tiff\", dir+title);\n",
    "} \n",
    "run(\"Close All\");\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ARA area ID map\n",
    "\n",
    "Now we can use the coordinates to get a map of the area IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlay\n",
    "from iss_preprocess.vis import plot_registration\n",
    "\n",
    "ops = np.load(processed_path / data_path / \"ops.npy\", allow_pickle=True).item()\n",
    "figure_folder = processed_path / data_path / \"figures\"\n",
    "REDO = True\n",
    "if REDO:\n",
    "    for roi in ops[\"use_rois\"]:\n",
    "        fig = plot_registration(data_path, roi, reference_prefix=\"genes_round_1_1\")\n",
    "        fig.savefig(figure_folder / f\"registration_roi{roi}.png\", dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ARA info for spots\n",
    "\n",
    "Finally we can get the ARA info just for the spots. We first need to get a dataframe of\n",
    "spots in the reference coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ops[\"use_rois\"][0]\n",
    "\n",
    "shift_right, shift_down, tile_shape = iss.pipeline.register_adjacent_tiles(\n",
    "    data_path, ref_coors=ops[\"ref_tile\"], prefix=\"genes_round_1_1\"\n",
    ")\n",
    "spots = iss.pipeline.merge_roi_spots(\n",
    "    data_path, shift_right, shift_down, tile_shape, iroi=roi, prefix=\"genes_round\"\n",
    ")\n",
    "iss.pipeline.ara_registration.spots_ara_infos(\n",
    "    data_path, spots, roi, atlas_size=10, inplace=True\n",
    ")\n",
    "print(f\"Spots in {len(spots['area_id'].unique())} areas.\")\n",
    "spots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spots\n",
    "from cricksaw_analysis import atlas_utils\n",
    "import bg_atlasapi as bga\n",
    "\n",
    "area_map = iss.pipeline.ara_registration.make_area_image(data_path, roi, atlas_size=10)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "add_borders = False  # add a flag because it's slow\n",
    "if add_borders:\n",
    "    reg_metadata = iss.pipeline.ara_registration.load_registration_reference_metadata(\n",
    "        data_path, roi=roi\n",
    "    )\n",
    "    scale = 1 / reg_metadata[\"downsample_ratio\"]\n",
    "    atlas_utils.plot_borders_and_areas(\n",
    "        ax,\n",
    "        area_map,\n",
    "        border_kwargs=dict(colors=\"black\", alpha=0.6, linewidths=0.1, zorder=100),\n",
    "    )\n",
    "else:\n",
    "    # no need to downsample\n",
    "    scale = 1\n",
    "\n",
    "\n",
    "atlas = bga.BrainGlobeAtlas(\"allen_mouse_100um\")\n",
    "labels = atlas.lookup_df\n",
    "skip = 100\n",
    "midline = spots.x.max() / 2\n",
    "for area_id, df in spots.iloc[::skip].groupby(\"area_id\"):\n",
    "    ax.scatter(df.x.values * scale, df.y.values * scale, zorder=1, s=1)\n",
    "    if area_id == 0:\n",
    "        # Out of brain\n",
    "        continue\n",
    "\n",
    "    label = labels.loc[labels.id == area_id, \"acronym\"].iloc[0]\n",
    "    left = df.loc[df.x < midline, [\"x\", \"y\"]].values * scale\n",
    "    if len(left) < 10:\n",
    "        continue\n",
    "    centre = np.nanmean(left, axis=0)\n",
    "    mi = np.nanmin(left, axis=0)\n",
    "    ma = np.nanmax(left, axis=0)\n",
    "    ar = np.sum((ma - mi) ** 2)\n",
    "    if ar / scale > 10e6:\n",
    "        ax.text(\n",
    "            *centre, s=label, verticalalignment=\"center\", horizontalalignment=\"center\"\n",
    "        )\n",
    "\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "leg = ax.legend(ncol=6, bbox_to_anchor=(1.04, 1), loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02c4ab6ff317cb8a885d2aa2247e2bd7c17b0a4a2d1482529ed329ad25df85a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
