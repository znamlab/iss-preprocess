{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iss_preprocess as iss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering DAPI_1_1 overviews to reference\n",
    "### using modified stitch and register which saves downsampled stitched images before shifting and pads images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from image_tools.registration import phase_correlation as mpc\n",
    "from image_tools.similarity_transforms import make_transform, transform_image\n",
    "\n",
    "def stitch_and_register(\n",
    "    data_path,\n",
    "    target_prefix,\n",
    "    reference_prefix=None,\n",
    "    roi=1,\n",
    "    downsample=3,\n",
    "    ref_ch=0,\n",
    "    target_ch=0,\n",
    "    estimate_scale=False,\n",
    "    estimate_rotation=True,\n",
    "    target_projection=None,\n",
    "    use_masked_correlation=False,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"Stitch target and reference stacks and align target to reference\n",
    "\n",
    "    To speed up registration, images are downsampled before estimating registration\n",
    "    parameters. These parameters are then applied to the full scale image.\n",
    "\n",
    "    The reference stack always use the \"projection\" from ops as suffix. The target uses\n",
    "    the same by default but that can be specified with `target_suffix`\n",
    "\n",
    "    This does not use ops['max_shift_rounds'].\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Relative path to data.\n",
    "        reference_prefix (str): Acquisition prefix to register the stitched image to.\n",
    "            Typically, \"genes_round_1_1\".\n",
    "        target_prefix (str): Acquisition prefix to register.\n",
    "        roi (int, optional): ROI ID to register (as specified in MicroManager).\n",
    "            Defaults to 1.\n",
    "        downsample (int, optional): Downsample factor for estimating registration\n",
    "            parameter. Defaults to 5.\n",
    "        ref_ch (int, optional): Channel of the reference image used for registration.\n",
    "            Defaults to 0.\n",
    "        target_ch (int, optional): Channel of the target image used for registration.\n",
    "            Defaults to 0.\n",
    "        estimate_scale (bool, optional): Whether to estimate scaling between target\n",
    "            and reference images. Defaults to False.\n",
    "        estimate_rotation (bool, optional): Whether to estimate rotation between target\n",
    "            and reference images. Defaults to True.\n",
    "        target_suffix (str, optional): Suffix to use for target stack. If None, will use\n",
    "            the value from ops. Defaults to None.\n",
    "        use_masked_correlation (bool, optional): Use masked correlation for registration.\n",
    "            Defaults to False.\n",
    "        debug (bool, optional): If True, return full xcorr. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Stitched target image after registration.\n",
    "        numpy.ndarray: Stitched reference image.\n",
    "        float: Estimate rotation angle.\n",
    "        tuple: Estimated X and Y shifts.\n",
    "        float: Estimated scaling factor.\n",
    "        dict: Debug information if `debug` is True.\n",
    "    \"\"\"\n",
    "    warnings.warn(\n",
    "        \"stitching is now done on registered tiles\", DeprecationWarning, stacklevel=2\n",
    "    )\n",
    "    ops = iss.io.load_ops(data_path)\n",
    "\n",
    "    if target_projection is None:\n",
    "        target_projection = ops[f\"{target_prefix.split('_')[0].lower()}_projection\"]\n",
    "    if reference_prefix is None:\n",
    "        reference_prefix = ops[\"reference_prefix\"]\n",
    "\n",
    "    ref_projection = ops[f\"{reference_prefix.split('_')[0].lower()}_projection\"]\n",
    "    if isinstance(target_ch, int):\n",
    "        target_ch = [target_ch]\n",
    "    stitched_stack_target = None\n",
    "    for ch in target_ch:\n",
    "        stitched = iss.pipeline.stitch_tiles(\n",
    "            data_path,\n",
    "            target_prefix,\n",
    "            suffix=target_projection,\n",
    "            roi=roi,\n",
    "            ich=ch,\n",
    "            shifts_prefix=reference_prefix,\n",
    "            correct_illumination=True,\n",
    "            allow_quick_estimate=True,\n",
    "        ).astype(\n",
    "            np.single\n",
    "        )  # to save memory\n",
    "        if stitched_stack_target is None:\n",
    "            stitched_stack_target = stitched\n",
    "        else:\n",
    "            stitched_stack_target += stitched\n",
    "    stitched_stack_target /= len(target_ch)\n",
    "\n",
    "    if isinstance(ref_ch, int):\n",
    "        ref_ch = [ref_ch]\n",
    "    stitched_stack_reference = None\n",
    "    for ch in ref_ch:\n",
    "        stitched = iss.pipeline.stitch_tiles(\n",
    "            data_path,\n",
    "            prefix=reference_prefix,\n",
    "            suffix=ref_projection,\n",
    "            roi=roi,\n",
    "            ich=ch,\n",
    "            shifts_prefix=reference_prefix,\n",
    "            correct_illumination=True,\n",
    "            register_channels=False,\n",
    "            allow_quick_estimate=True,\n",
    "        ).astype(np.single)\n",
    "        if stitched_stack_reference is None:\n",
    "            stitched_stack_reference = stitched\n",
    "        else:\n",
    "            stitched_stack_reference += stitched\n",
    "    stitched_stack_reference /= len(ref_ch)\n",
    "\n",
    "    # If they have different shapes, pad the smaller image to the size of the larger image\n",
    "    if stitched_stack_target.shape != stitched_stack_reference.shape:\n",
    "        warnings.warn(\"Stitched stacks have different shapes. Padding to match.\")\n",
    "        target_shape = stitched_stack_target.shape\n",
    "        reference_shape = stitched_stack_reference.shape\n",
    "        if target_shape < reference_shape:\n",
    "            padding = [(0, ref - targ) for targ, ref in zip(target_shape, reference_shape)]\n",
    "            stitched_stack_target = np.pad(stitched_stack_target, padding, mode='constant', constant_values=0)\n",
    "            fshape = reference_shape\n",
    "        else:\n",
    "            padding = [(0, targ - ref) for targ, ref in zip(target_shape, reference_shape)]\n",
    "            stitched_stack_reference = np.pad(stitched_stack_reference, padding, mode='constant', constant_values=0)\n",
    "            fshape = target_shape\n",
    "    else:\n",
    "        fshape = stitched_stack_target.shape\n",
    "\n",
    "    def prep_stack(stack, downsample):\n",
    "        if stack.dtype != bool:\n",
    "            ma = np.nanpercentile(stack, 99)\n",
    "            stack = np.clip(stack, 0, ma)\n",
    "            stack = stack / ma\n",
    "        # downsample\n",
    "        new_size = np.array(stack.shape) // downsample\n",
    "        stack = transform.resize(stack, new_size)\n",
    "        return stack\n",
    "\n",
    "    # setup common args for registration\n",
    "    kwargs = dict(\n",
    "        angle_range=1.0,\n",
    "        niter=3,\n",
    "        nangles=11,\n",
    "        upsample=False,\n",
    "        debug=debug,\n",
    "        max_shift=ops[\"max_shift2ref\"] // downsample,\n",
    "        min_shift=0,\n",
    "        reference=prep_stack(stitched_stack_reference, downsample),\n",
    "        target=prep_stack(stitched_stack_target, downsample),\n",
    "    )\n",
    "    if use_masked_correlation:\n",
    "        kwargs[\"target_mask\"] = prep_stack(stitched_stack_target != 0, downsample)\n",
    "        kwargs[\"reference_mask\"] = prep_stack(stitched_stack_reference != 0, downsample)\n",
    "\n",
    "    if estimate_scale and estimate_rotation:\n",
    "        out = iss.pipeline.estimate_scale_rotation_translation(\n",
    "            scale_range=0.01,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if debug:\n",
    "            angle, shift, scale, debug_dict = out\n",
    "        else:\n",
    "            angle, shift, scale = out\n",
    "    elif estimate_rotation:\n",
    "        out = iss.pipeline.estimate_rotation_translation(\n",
    "            **kwargs,\n",
    "        )\n",
    "        if debug:\n",
    "            angle, shift, debug_dict = out\n",
    "        else:\n",
    "            angle, shift = out\n",
    "        scale = 1\n",
    "    else:\n",
    "        shift, _, _, _ = mpc.phase_correlation(kwargs[\"reference\"], kwargs[\"target\"])\n",
    "        scale = 1\n",
    "        angle = 0\n",
    "    shift *= downsample\n",
    "\n",
    "    stitched_stack_target_transformed = transform_image(\n",
    "        stitched_stack_target, scale=scale, angle=angle, shift=shift\n",
    "    )\n",
    "\n",
    "    fname = f\"{target_prefix}_roi{roi}_tform_to_ref.npz\"\n",
    "    print(f\"Saving {fname} in the reg folder\")\n",
    "    np.savez(\n",
    "        iss.io.get_processed_path(data_path) / \"reg\" / fname,\n",
    "        angle=angle,\n",
    "        shift=shift,\n",
    "        scale=scale,\n",
    "        stitched_stack_shape=fshape,\n",
    "    )\n",
    "    output = [stitched_stack_target, stitched_stack_target_transformed, stitched_stack_reference, angle, shift, scale]\n",
    "    if debug:\n",
    "        output.append(debug_dict)\n",
    "    return tuple(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run the above in parallel \n",
    "### (takes long time, could be slurmed, don't re-run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iss_preprocess as iss\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def prep_stack(stack, downsample):\n",
    "    if stack.dtype != bool:\n",
    "        ma = np.nanpercentile(stack, 99)\n",
    "        stack = np.clip(stack, 0, ma)\n",
    "        stack = stack / ma\n",
    "    # downsample\n",
    "    new_size = np.array(stack.shape) // downsample\n",
    "    stack = transform.resize(stack, new_size)\n",
    "    return stack\n",
    "\n",
    "def process_chamber_roi(args):\n",
    "    chamber, roi = args\n",
    "    data_path = f\"becalia_rabies_barseq/BRAC8498.3e/chamber_{chamber}/\"\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    print(f\"Doing registration for chamber {chamber} ROI {roi}\")\n",
    "    (\n",
    "        target_image,\n",
    "        target_image_shifted,\n",
    "        ref_image,\n",
    "        angle,\n",
    "        shifts,\n",
    "        scale\n",
    "    ) = stitch_and_register(\n",
    "        data_path,\n",
    "        target_prefix=\"DAPI_1_1\",\n",
    "        reference_prefix=None,\n",
    "        roi=roi,\n",
    "        downsample=50,\n",
    "        ref_ch=3,\n",
    "        target_ch=3,\n",
    "        estimate_scale=False,\n",
    "        estimate_rotation=False,\n",
    "        target_projection=None,\n",
    "        use_masked_correlation=False,\n",
    "        debug=False,\n",
    "    )\n",
    "    save_path = processed_path / \"figures\" / \"DAPI_1_1\"\n",
    "    save_path.mkdir(exist_ok=True)\n",
    "    downsampled_target = prep_stack(target_image, 50)\n",
    "    tifffile.imsave(save_path / f\"DAPI_1_1_roi{roi}.tif\", downsampled_target)\n",
    "    downsampled_target_shifted = prep_stack(target_image_shifted, 50)\n",
    "    tifffile.imsave(save_path / f\"DAPI_1_1_roi{roi}_shifted.tif\", downsampled_target_shifted)\n",
    "    downsampled_ref = prep_stack(ref_image, 50)\n",
    "    tifffile.imsave(save_path / f\"hyb_roi{roi}_ref.tif\", downsampled_ref)\n",
    "    print(f\"Finished registration for chamber {chamber} ROI {roi}\")\n",
    "    print(f\"Angle: {angle}, Shifts: {shifts}, Scale: {scale}\")\n",
    "\n",
    "if False:\n",
    "    # Parameters\n",
    "    chambers = [\"07\", \"08\", \"09\", \"10\"]\n",
    "    rois = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    tasks = [(chamber, roi) for chamber in chambers for roi in rois]\n",
    "\n",
    "    # Run the multiprocessing pool\n",
    "    with Pool(processes=20) as pool:  # Adjust the number of processes as needed\n",
    "        pool.map(process_chamber_roi, tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results of registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "\n",
    "chamber = \"07\"\n",
    "data_path = f\"becalia_rabies_barseq/BRAC8498.3e/chamber_{chamber}/\"\n",
    "processed_path = iss.io.get_processed_path(data_path)\n",
    "\n",
    "# Define the number of rows and columns for the subplots\n",
    "num_rois = 10\n",
    "cols = 5\n",
    "rows = (num_rois + cols - 1) // cols\n",
    "\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(20, 10), dpi=300)\n",
    "\n",
    "for i, roi in enumerate(range(1, num_rois + 1)):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    ax = axs[row, col]\n",
    "\n",
    "    target_image_shifted = tifffile.imread(processed_path / \"figures\" / \"DAPI_1_1\" / f\"DAPI_1_1_roi{roi}_shifted.tif\")\n",
    "    ax.imshow(target_image_shifted, cmap=\"Greens_r\")\n",
    "    try:\n",
    "        ref_image = tifffile.imread(processed_path / \"figures\" / \"DAPI_1_1\" / f\"hyb_roi{roi}_ref.tif\")\n",
    "        ax.imshow(ref_image, cmap=\"Reds_r\", alpha=0.5)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ROI {roi} not found\")\n",
    "        pass\n",
    "    ax.set_title(f\"ROI {roi}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide any empty subplots\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axs.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual fixes\n",
    "\n",
    "#ch7 roi 6\n",
    "[-24450, -10900]\n",
    "#ch7 roi 8\n",
    "[-24000, -10250]\n",
    "#ch8 roi 9\n",
    "(0.9170526315789473, 0.0, array([ -35.5, -240.5])) -1775, -12025\n",
    "#ch9 roi 7\n",
    "[1425, -17425]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make cropped and shifted ara coord images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_tools.similarity_transforms import transform_image\n",
    "\n",
    "def crop_to_non_cval(im, cval: float = 0.0):\n",
    "    \"\"\"\n",
    "    Crop the image to only the part that isn't filled in by cval.\n",
    "    Args:\n",
    "        im (npt.NDArray): Transformed image (can be 2D or 3D with channels first)\n",
    "        cval (float): Value to fill in for pixels outside of the image\n",
    "    Returns:\n",
    "        npt.NDArray: Cropped image\n",
    "    \"\"\"\n",
    "    if im.ndim == 3:\n",
    "        # Assume channels are the first dimension\n",
    "        mask = np.any(im != cval, axis=0)\n",
    "    else:\n",
    "        mask = im != cval\n",
    "    \n",
    "    coords = np.argwhere(mask)\n",
    "    \n",
    "    if coords.size == 0:\n",
    "        return im\n",
    "    \n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0) + 1\n",
    "    \n",
    "    if im.ndim == 3:\n",
    "        cropped_im = im[:, y_min:y_max, x_min:x_max]\n",
    "    else:\n",
    "        cropped_im = im[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    return cropped_im\n",
    "\n",
    "if False:\n",
    "    ara_downsample_rate = 8\n",
    "\n",
    "    ch_offset = 0\n",
    "    for chamber in [\"07\", \"08\", \"09\", \"10\"]:\n",
    "        data_path = f\"becalia_rabies_barseq/BRAC8498.3e/chamber_{chamber}/\"\n",
    "        processed_path = iss.io.get_processed_path(data_path)\n",
    "        for roi in [1,2,3,4,5,6,7,8,9,10]:\n",
    "            shifts = np.load(processed_path / \"reg\" / f\"DAPI_1_1_roi{roi}_tform_to_ref.npz\")\n",
    "            #account for downsampling\n",
    "            shifts[\"shift\"] / ara_downsample_rate\n",
    "            ara_im = tifffile.imread(processed_path / \"register_to_ara\" / \"ara_coordinates\" / f\"chamber_{chamber}_r{roi}_sl{str(roi+ch_offset).zfill(3)}.ome.tif_Coords.tif\")\n",
    "            target_shifted = transform_image(\n",
    "                ara_im, scale=1, angle=0, shift=(shifts[\"shift\"] / 8)\n",
    "            )\n",
    "            cropped_image = crop_to_non_cval(target_shifted, cval=0.0)\n",
    "            #shift order from [z,x,y] to [x,y,z]\n",
    "            cropped_image = np.moveaxis(cropped_image, 0, -1)\n",
    "            iss.io.write_stack(cropped_image, processed_path / \"register_to_ara\" / \"ara_coordinates\" / f\"chamber_{chamber}_r{roi}_sl{str(roi+ch_offset).zfill(3)}_registered.tif\", dtype=\"float32\",  clip=False)\n",
    "            print(f\"Saved {processed_path / 'register_to_ara' / 'ara_coordinates' / f'chamber_{chamber}_r{roi}_sl{str(roi+ch_offset).zfill(3)}_registered.tif'}\")\n",
    "        ch_offset += 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign ARA coords to spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "for chamber in [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    print(f\"Doing registration for {data_path}\")\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path)\n",
    "    rois = roi_dims[:,0]\n",
    "    print(rois)\n",
    "    for roi in tqdm(rois, total=len(rois)):   \n",
    "        gene_spots = pd.read_pickle(processed_path / f\"genes_round_spots_{roi}.pkl\")\n",
    "        ara_gene_spots = iss.pipeline.spots_ara_infos(data_path, gene_spots, roi, atlas_size=10, acronyms=True, inplace=True)\n",
    "        pd.to_pickle(ara_gene_spots, processed_path / f\"ara_genes_round_spots_{roi}.pkl\")\n",
    "\n",
    "        barcode_spots = pd.read_pickle(processed_path / f\"barcode_round_spots_{roi}.pkl\")\n",
    "        ara_barcode_spots = iss.pipeline.spots_ara_infos(data_path, barcode_spots, roi, atlas_size=10, acronyms=True, inplace=True)\n",
    "        pd.to_pickle(ara_barcode_spots, processed_path / f\"ara_barcode_round_spots_{roi}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "for chamber in [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    print(f\"Doing registration for {data_path}\")\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path)\n",
    "    rois = roi_dims[:,0]\n",
    "    print(rois)\n",
    "    for roi in tqdm(rois, total=len(rois)):   \n",
    "        barcode_spots = pd.DataFrame(np.load(processed_path / \"manual_starter_click\" / f\"BRAC8498.3e_{chamber}_{roi}_rabies_spots.npy\", allow_pickle=True), columns=[\"x\", \"y\",\"barcode_id\", \"mask_id\", \"barcode\"])\n",
    "        barcode_spots[\"y\"] = barcode_spots[\"y\"].astype(np.float64)\n",
    "        barcode_spots[\"x\"] = barcode_spots[\"x\"].astype(np.float64)\n",
    "        ara_barcode_filtered_spots = iss.pipeline.spots_ara_infos(data_path, barcode_spots, roi, atlas_size=10, acronyms=True, inplace=True)\n",
    "        pd.to_pickle(ara_barcode_filtered_spots, processed_path / f\"ara_barcode_filtered_spots_{roi}.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "for chamber in [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    print(f\"Doing registration for {data_path}\")\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path)\n",
    "    rois = roi_dims[:,0]\n",
    "    print(rois)\n",
    "    for roi in tqdm(rois, total=len(rois)):   \n",
    "        starter_cells = pd.read_csv(processed_path.parent / \"analysis\" / \"starter_cells\" / f\"starter_cells_BRAC8498.3e_{chamber}_roi_{roi}.csv\", index_col=0)\n",
    "        starter_cells.columns = [\"y\", \"x\"]\n",
    "        ara_starter_cells = iss.pipeline.spots_ara_infos(data_path, starter_cells, roi, atlas_size=10, acronyms=True, inplace=True)\n",
    "        pd.to_pickle(ara_starter_cells, processed_path / f\"ara_starter_cells_{roi}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all spots into one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the chambers and the prefix\n",
    "chambers = [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]\n",
    "prefix = \"DAPI_1_1\"\n",
    "base_path = \"becalia_rabies_barseq/BRAC8498.3e/\"\n",
    "# Initialize an empty list to collect dataframes\n",
    "dataframes = []\n",
    "\n",
    "for chamber in chambers:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    print(f\"Loading data for {data_path}\")\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    # Get the ROI dimensions\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path, prefix)\n",
    "    rois = roi_dims[:, 0]\n",
    "    \n",
    "    for roi in tqdm(rois, total=len(rois)):\n",
    "        # Load the ara_genes_round_spots PKL\n",
    "        pkl_path = os.path.join(processed_path, f\"ara_genes_round_spots_{roi}.pkl\")\n",
    "        if os.path.exists(pkl_path):\n",
    "            ara_gene_spots = pd.read_pickle(pkl_path)\n",
    "            # Add columns for chamber and roi\n",
    "            ara_gene_spots['chamber'] = chamber\n",
    "            ara_gene_spots['roi'] = roi\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(ara_gene_spots)\n",
    "        else:\n",
    "            print(f\"File not found: {pkl_path}\")\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_ara_gene_spots = pd.concat(dataframes, ignore_index=True)\n",
    "all_ara_gene_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# Define the chambers and the prefix\n",
    "chambers = [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]\n",
    "prefix = \"DAPI_1_1\"\n",
    "base_path = \"becalia_rabies_barseq/BRAC8498.3e/\"\n",
    "# Initialize an empty list to collect dataframes\n",
    "dataframes = []\n",
    "for chamber in chambers:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    print(f\"Loading data for {data_path}\")\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    # Get the ROI dimensions\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path, prefix)\n",
    "    rois = roi_dims[:, 0]\n",
    "    \n",
    "    for roi in tqdm(rois, total=len(rois)):\n",
    "        # Load the ara_genes_round_spots PKL\n",
    "        pkl_path = os.path.join(processed_path, f\"ara_barcode_filtered_spots_{roi}.pkl\")\n",
    "        if os.path.exists(pkl_path):\n",
    "            ara_barcode_spots = pd.read_pickle(pkl_path)\n",
    "            # Add columns for chamber and roi\n",
    "            ara_barcode_spots['chamber'] = chamber\n",
    "            ara_barcode_spots['roi'] = roi\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(ara_barcode_spots)\n",
    "        else:\n",
    "            print(f\"File not found: {pkl_path}\")\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_ara_barcode_spots = pd.concat(dataframes, ignore_index=True)\n",
    "all_ara_barcode_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# Define the chambers and the prefix\n",
    "chambers = [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]\n",
    "prefix = \"DAPI_1_1\"\n",
    "base_path = \"becalia_rabies_barseq/BRAC8498.3e/\"\n",
    "# Initialize an empty list to collect dataframes\n",
    "dataframes = []\n",
    "for chamber in chambers:\n",
    "    data_path = \"becalia_rabies_barseq/BRAC8498.3e/\" + chamber + \"/\"\n",
    "    print(f\"Loading data for {data_path}\")\n",
    "    processed_path = iss.io.get_processed_path(data_path)\n",
    "    # Get the ROI dimensions\n",
    "    roi_dims = iss.io.get_roi_dimensions(data_path, prefix)\n",
    "    rois = roi_dims[:, 0]\n",
    "    \n",
    "    for roi in tqdm(rois, total=len(rois)):\n",
    "        # Load the ara_genes_round_spots PKL\n",
    "        pkl_path = os.path.join(processed_path, f\"ara_starter_cells_{roi}.pkl\")\n",
    "        if os.path.exists(pkl_path):\n",
    "            ara_starter_cells = pd.read_pickle(pkl_path)\n",
    "            # Add columns for chamber and roi\n",
    "            ara_starter_cells['chamber'] = chamber\n",
    "            ara_starter_cells['roi'] = roi\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(ara_starter_cells)\n",
    "        else:\n",
    "            print(f\"File not found: {pkl_path}\")\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_ara_starter_cells = pd.concat(dataframes, ignore_index=True)\n",
    "all_ara_starter_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform coords for 2D plotting\n",
    "### Using chamber_07 ROI 1 as reference, transform all other ROI's raw x, y coords using least squares into a common 2D framework using the relation between each ROI's raw and ara coords\n",
    "This allows checking of registration fit between planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "roi_reference = 1 \n",
    "\n",
    "df = all_ara_gene_spots.copy()\n",
    "df['z'] = 0\n",
    "\n",
    "# Filter rows where roi is equal to 1 and chamber is equal to 07\n",
    "df_roi_1 = df[(df['roi'] == roi_reference) & (df['chamber'] == 'chamber_07')]\n",
    "\n",
    "# Extract coordinate values for roi = 1\n",
    "x = df_roi_1['x'].values\n",
    "y = df_roi_1['y'].values\n",
    "z = df_roi_1['z'].values\n",
    "ara_x = df_roi_1['ara_x'].values\n",
    "ara_y = df_roi_1['ara_y'].values\n",
    "ara_z = df_roi_1['ara_z'].values\n",
    "\n",
    "A = np.column_stack((ara_x, ara_y, ara_z))\n",
    "b = np.column_stack((x, y, z))\n",
    "\n",
    "T, residuals, _, _ = lstsq(A, b)\n",
    "\n",
    "# Apply the transformation matrix to rows where roi is not equal to 1\n",
    "df_roi_not_1 = df[df['roi'] != roi_reference]\n",
    "\n",
    "# Extract coordinate values for roi != 1\n",
    "ara_x_new = df_roi_not_1['ara_x'].values\n",
    "ara_y_new = df_roi_not_1['ara_y'].values\n",
    "ara_z_new = df_roi_not_1['ara_z'].values\n",
    "\n",
    "# Apply the transformation matrix T to the new data\n",
    "coordinates_new = np.column_stack((ara_x_new, ara_y_new, ara_z_new))\n",
    "transformed_coordinates = np.dot(coordinates_new, T)\n",
    "\n",
    "# Extract the transformed coordinates into separate arrays\n",
    "x_new = transformed_coordinates[:, 0]\n",
    "y_new = transformed_coordinates[:, 1]\n",
    "z_new = transformed_coordinates[:, 2]\n",
    "\n",
    "# Create new columns 'x', 'y', 'z' in df_roi_not_1 with the transformed coordinates\n",
    "df_roi_not_1['x'] = x_new\n",
    "df_roi_not_1['y'] = y_new\n",
    "df_roi_not_1['z'] = z_new\n",
    "\n",
    "# Combine the modified rows back with the original DataFrame\n",
    "df_transformed_genes = pd.concat([df_roi_1, df_roi_not_1])\n",
    "\n",
    "# Print the transformed DataFrame\n",
    "df_transformed_genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spots outside brain\n",
    "df_transformed_genes = df_transformed_genes[df_transformed_genes['area_acronym'] != 'outside']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all ROIs in 2D if desired\n",
    "### (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chambers and rois\n",
    "chambers = [\"chamber_07\", \"chamber_08\", \"chamber_09\", \"chamber_10\"]\n",
    "rois = list(range(1, 11))\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axs = plt.subplots(len(chambers), len(rois), figsize=(20, 15))\n",
    "\n",
    "for i, chamber in tqdm(enumerate(chambers), total=len(chambers)):\n",
    "    for j, roi in tqdm(enumerate(rois), total=len(rois)):\n",
    "        # Filter the DataFrame for the current chamber and roi\n",
    "        df_filtered = df_transformed_genes[(df_transformed_genes['chamber'] == chamber) & (df_transformed_genes['roi'] == roi)]\n",
    "        \n",
    "        # Plot the data\n",
    "        axs[i, j].scatter(df_filtered['x'], df_filtered['y'], s=0.01, alpha=0.05, c=\"black\")\n",
    "        axs[i, j].set_title(f'{chamber}, ROI: {roi}')\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_aspect('equal')\n",
    "        # Optionally set labels if desired\n",
    "        if i == len(chambers) - 1:\n",
    "            axs[i, j].set_xlabel('X')\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel('Y')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or plot any two planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    df_transformed_genes[(df_transformed_genes[\"roi\"]==1)&(df_transformed_genes[\"chamber\"]==\"chamber_07\")][\"x\"],\n",
    "    df_transformed_genes[(df_transformed_genes[\"roi\"]==1)&(df_transformed_genes[\"chamber\"]==\"chamber_07\")][\"y\"],\n",
    "    s=0.1, alpha=0.1)\n",
    "\n",
    "plt.scatter(\n",
    "    df_transformed_genes[(df_transformed_genes[\"roi\"]==2)&(df_transformed_genes[\"chamber\"]==\"chamber_07\")][\"x\"],\n",
    "    df_transformed_genes[(df_transformed_genes[\"roi\"]==2)&(df_transformed_genes[\"chamber\"]==\"chamber_07\")][\"y\"],\n",
    "    s=0.1, alpha=0.03, c=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive 3D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assuming df_transformed_genes is your DataFrame and already defined\n",
    "\n",
    "# Factorize the area_id column\n",
    "df_transformed_genes['area_ids_continuous'] = pd.factorize(df_transformed_genes['area_id'])[0].astype(str)\n",
    "\n",
    "# Define the number of points to plot\n",
    "subset_size = 100000\n",
    "\n",
    "# Randomly select a subset of points\n",
    "df_subset = df_transformed_genes.sample(n=subset_size)\n",
    "df_subset = df_subset.sort_values(by='area_acronym')\n",
    "# Create a list of colors using the tab20 colormap from matplotlib\n",
    "tab20 = plt.get_cmap('tab20').colors\n",
    "tab20_hex = [mcolors.rgb2hex(color) for color in tab20]\n",
    "\n",
    "# Generate a list of colors mapped to the unique area_ids_continuous\n",
    "unique_area_ids = df_subset['area_ids_continuous'].unique()\n",
    "color_map = {area_id: tab20_hex[i % len(tab20_hex)] for i, area_id in enumerate(unique_area_ids)}\n",
    "\n",
    "# Apply the color mapping to the DataFrame\n",
    "df_subset['color'] = df_subset['area_ids_continuous'].map(color_map)\n",
    "\n",
    "# Create the scatter plot using Plotly Express\n",
    "fig = px.scatter_3d(\n",
    "    df_subset,\n",
    "    x='ara_x',\n",
    "    y='ara_y',\n",
    "    z='ara_z',\n",
    "    color='area_ids_continuous',\n",
    "    color_discrete_sequence=tab20_hex,\n",
    "    title='Interactive 3D Scatter Plot Colored by area_ids_continuous',\n",
    "    width=2000,\n",
    "    height=1200\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "area_acronym_map = df_transformed_genes.set_index('area_ids_continuous')['area_acronym'].to_dict()\n",
    "fig.for_each_trace(lambda t: t.update(name = area_acronym_map[t.name]))\n",
    "\n",
    "\n",
    "# Update legend marker size\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        itemsizing='constant',\n",
    "        itemclick='toggleothers',\n",
    "        itemdoubleclick='toggle',\n",
    "        title_text='Legend',\n",
    "        font=dict(size=12),\n",
    "        traceorder='normal'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove the background grid and axes\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        bgcolor='white'  # Set the background color to white\n",
    "    )\n",
    ")\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assuming df_transformed_genes is your DataFrame and already defined\n",
    "\n",
    "# Factorize the area_id column\n",
    "all_ara_starter_cells['area_ids_continuous'] = pd.factorize(all_ara_starter_cells['area_id'])[0].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "df_subset = all_ara_starter_cells\n",
    "df_subset = df_subset.sort_values(by='area_acronym')\n",
    "# Create a list of colors using the tab20 colormap from matplotlib\n",
    "tab20 = plt.get_cmap('tab20').colors\n",
    "tab20_hex = [mcolors.rgb2hex(color) for color in tab20]\n",
    "\n",
    "# Generate a list of colors mapped to the unique area_ids_continuous\n",
    "unique_area_ids = df_subset['area_ids_continuous'].unique()\n",
    "color_map = {area_id: tab20_hex[i % len(tab20_hex)] for i, area_id in enumerate(unique_area_ids)}\n",
    "\n",
    "# Apply the color mapping to the DataFrame\n",
    "df_subset['color'] = df_subset['area_ids_continuous'].map(color_map)\n",
    "\n",
    "# Create the scatter plot using Plotly Express\n",
    "fig = px.scatter_3d(\n",
    "    df_subset,\n",
    "    x='ara_x',\n",
    "    y='ara_y',\n",
    "    z='ara_z',\n",
    "    color='area_ids_continuous',\n",
    "    color_discrete_sequence=tab20_hex,\n",
    "    title='Interactive 3D Scatter Plot Colored by area_ids_continuous',\n",
    "    width=2000,\n",
    "    height=1200\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "area_acronym_map = all_ara_starter_cells.set_index('area_ids_continuous')['area_acronym'].to_dict()\n",
    "fig.for_each_trace(lambda t: t.update(name = area_acronym_map[t.name]))\n",
    "\n",
    "\n",
    "# Update legend marker size\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        itemsizing='constant',\n",
    "        itemclick='toggleothers',\n",
    "        itemdoubleclick='toggle',\n",
    "        title_text='Legend',\n",
    "        font=dict(size=12),\n",
    "        traceorder='normal'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove the background grid and axes\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        bgcolor='white'  # Set the background color to white\n",
    "    )\n",
    ")\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assuming all_ara_barcode_spots is your DataFrame and already defined\n",
    "# Factorize the barcode column to create universal_barcode_id\n",
    "all_ara_barcode_spots['universal_barcode_id'] = pd.factorize(all_ara_barcode_spots['barcode'])[0].astype(str)\n",
    "\n",
    "# Filter out rows where area_acronym is 'outside'\n",
    "all_ara_barcode_spots = all_ara_barcode_spots[all_ara_barcode_spots['area_acronym'] != 'outside']\n",
    "\n",
    "df_subset = all_ara_barcode_spots\n",
    "df_subset = df_subset.sort_values(by='area_acronym')\n",
    "\n",
    "# Create a list of colors using the tab20 colormap from matplotlib\n",
    "tab20 = plt.get_cmap('tab20').colors\n",
    "tab20_hex = [mcolors.rgb2hex(color) for color in tab20]\n",
    "\n",
    "# Generate a list of colors mapped to the unique universal_barcode_id\n",
    "unique_barcode_ids = df_subset['universal_barcode_id'].unique()\n",
    "color_map = {barcode_id: tab20_hex[i % len(tab20_hex)] for i, barcode_id in enumerate(unique_barcode_ids)}\n",
    "\n",
    "# Apply the color mapping to the DataFrame\n",
    "df_subset['color'] = df_subset['universal_barcode_id'].map(color_map)\n",
    "\n",
    "# Count the occurrences of each barcode and sort them\n",
    "barcode_counts = df_subset['universal_barcode_id'].value_counts()\n",
    "sorted_barcodes = barcode_counts.index.tolist()\n",
    "\n",
    "# Create the scatter plot using Plotly Express\n",
    "fig = px.scatter_3d(\n",
    "    df_subset,\n",
    "    x='ara_x',\n",
    "    y='ara_y',\n",
    "    z='ara_z',\n",
    "    color='universal_barcode_id',\n",
    "    category_orders={'universal_barcode_id': sorted_barcodes},\n",
    "    color_discrete_sequence=tab20_hex,\n",
    "    title='Interactive 3D Scatter Plot Colored by universal_barcode_id',\n",
    "    width=2000,\n",
    "    height=1200\n",
    ")\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "# Map barcode IDs to the actual barcode sequences\n",
    "barcode_id_map = all_ara_barcode_spots.set_index('universal_barcode_id')['barcode'].to_dict()\n",
    "fig.for_each_trace(lambda t: t.update(name=barcode_id_map[t.name]))\n",
    "\n",
    "# Update legend marker size\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        itemsizing='constant',\n",
    "        itemclick='toggleothers',\n",
    "        itemdoubleclick='toggle',\n",
    "        title_text='Legend',\n",
    "        font=dict(size=12),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove the background grid and axes\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            visible=False\n",
    "        ),\n",
    "        bgcolor='white'  # Set the background color to white\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
