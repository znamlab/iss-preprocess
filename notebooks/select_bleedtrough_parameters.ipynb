{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select bleedthrough parameters\n",
    "\n",
    "To set up base calling, we need to create bleed-through matrices. This is done by \n",
    "selecting a threshold for spot detection and one for filtering isolated spots. This \n",
    "notebook will help you select the best threshold for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import iss_preprocess as iss\n",
    "import iss_preprocess.io.load\n",
    "import iss_preprocess.pipeline.register\n",
    "\n",
    "data_path = \"becalia_rabies_barseq/BRAC8323.6g/chamber_16\"\n",
    "prefix = \"genes_round\"\n",
    "ref_tile_index = 0  # which of the reference tiles do we want to use for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = iss.io.load.load_ops(data_path)\n",
    "short_pref = prefix.split(\"_\")[0]\n",
    "ref_tiles = ops[f\"{short_pref}_ref_tiles\"]\n",
    "print(f\"{len(ref_tiles)} reference tiles found. Using {ref_tile_index}.\")\n",
    "ref_tile = ref_tiles[ref_tile_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading registered data for {ref_tile}\")\n",
    "stack, _ = iss.pipeline.register.load_and_register_sequencing_tile(\n",
    "    data_path,\n",
    "    ref_tile,\n",
    "    filter_r=ops[\"filter_r\"],\n",
    "    prefix=prefix,\n",
    "    suffix=ops[f\"{short_pref}_projection\"],\n",
    "    nrounds=ops[f\"{prefix}s\"],\n",
    "    correct_channels=ops[f\"{short_pref}_correct_channels\"],\n",
    "    corrected_shifts=ops[\"corrected_shifts\"],\n",
    "    correct_illumination=False,\n",
    ")\n",
    "stack = stack[:, :, np.argsort(ops[\"camera_order\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making reference image using STD\")\n",
    "reference = np.std(stack, axis=(2, 3))\n",
    "reference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot detection\n",
    "\n",
    "First step is to detect some spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.segment.spots import detect_spots\n",
    "\n",
    "ops = iss.io.load.load_ops(data_path)\n",
    "detection_threshold = ops[f\"{short_pref}_detection_threshold\"]\n",
    "print(f\"detection_threshold: {detection_threshold}\")\n",
    "spots = detect_spots(reference, threshold=detection_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the place with the highest density of spots, just for plotting\n",
    "x, y = spots[\"x\"].values, spots[\"y\"].values\n",
    "# Create a grid of potential disk centers\n",
    "x_grid, y_grid = np.meshgrid(\n",
    "    np.arange(200, stack.shape[1] - 200, 25),\n",
    "    np.arange(200, stack.shape[0] - 200, 25),\n",
    ")\n",
    "# Compute the Euclidean distance from each spot to each potential center\n",
    "distances = np.sqrt((x[:, None, None] - x_grid) ** 2 + (y[:, None, None] - y_grid) ** 2)\n",
    "# Count the number of spots within a 100px radius for each potential center\n",
    "counts = np.sum(distances <= 50, axis=0)\n",
    "center = np.unravel_index(counts.argmax(), counts.shape)\n",
    "center = (x_grid[center], y_grid[center])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.vis.utils import plot_matrix_with_colorbar\n",
    "from iss_preprocess.vis.vis import round_to_rgb\n",
    "\n",
    "w = 200\n",
    "extent = [[center[1] - w, center[1] + w], [center[0] - w, center[0] + w]]\n",
    "\n",
    "valid_spots = spots[\n",
    "    (spots.x > extent[1][0])\n",
    "    & (spots.x < extent[1][1])\n",
    "    & (spots.y > extent[0][0])\n",
    "    & (spots.y < extent[0][1])\n",
    "]\n",
    "\n",
    "rgb = round_to_rgb(\n",
    "    stack,\n",
    "    1,\n",
    "    extent=extent,\n",
    "    channel_colors=([1, 0, 0], [0, 1, 0], [1, 0, 1], [0, 1, 1]),\n",
    "    vmax=np.percentile(stack[..., 0], 99.99, axis=(0, 1)),\n",
    "    vmin=np.percentile(stack[..., 0], 0.2, axis=(0, 1)),\n",
    ")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# make a colorbar and hide it to have axis the same size\n",
    "cax, cb = plot_matrix_with_colorbar(rgb, axes[0])\n",
    "cax.clear()\n",
    "cax.axis(\"off\")\n",
    "axes[0].set_title(\"Raw data, round 1\")\n",
    "ref_part = reference[slice(*extent[0]), slice(*extent[1])]\n",
    "cax, cb = plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[1],\n",
    "    cmap=\"viridis\",\n",
    "    vmax=np.percentile(reference, 99.999),\n",
    "    vmin=np.percentile(reference, 0.2),\n",
    ")\n",
    "axes[1].contour(ref_part, levels=[detection_threshold], colors=\"r\", linewidths=0.5)\n",
    "cax.axhline(detection_threshold, color=\"r\", lw=2)\n",
    "axes[1].set_title(\"Standard deviation projection\")\n",
    "for ax in axes:\n",
    "    ax.scatter(\n",
    "        valid_spots.x - extent[1][0],\n",
    "        valid_spots.y - extent[0][0],\n",
    "        s=2,\n",
    "        c=\"k\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select isolated spots\n",
    "\n",
    "We keep only spots with a minimum distance to the next spot. This is done by measuring\n",
    "the fluorescence in an annulus around each spot and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.coppafish import annulus\n",
    "from iss_preprocess.segment import detect_isolated_spots\n",
    "\n",
    "ops = iss.io.load.load_ops(data_path)\n",
    "isolation_threshold = ops[f\"{short_pref}_isolation_threshold\"]\n",
    "print(isolation_threshold)\n",
    "annulus_r = (3, 7)\n",
    "strel = annulus(annulus_r[0], annulus_r[1])\n",
    "strel = strel / np.sum(strel)\n",
    "annulus_image = scipy.ndimage.correlate(reference, strel)\n",
    "isolated = annulus_image[spots[\"y\"], spots[\"x\"]] < isolation_threshold\n",
    "isolated_spots = spots[isolated]\n",
    "non_isolated_spots = spots[~isolated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annulus_part = annulus_image[slice(*extent[0]), slice(*extent[1])]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[0],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    ")\n",
    "axes[0].set_title(\"Standard deviation projection\")\n",
    "\n",
    "cax, cb = plot_matrix_with_colorbar(\n",
    "    annulus_part,\n",
    "    axes[1],\n",
    "    vmax=np.percentile(annulus_part, 99.999),\n",
    "    vmin=np.percentile(annulus_part, 0.05),\n",
    ")\n",
    "print(isolation_threshold)\n",
    "cax.axhline(isolation_threshold, color=\"r\", lw=2)\n",
    "if isolation_threshold < cax.get_ylim()[0]:\n",
    "    cax.set_ylim(isolation_threshold, cax.get_ylim()[1])\n",
    "if isolation_threshold > cax.get_ylim()[1]:\n",
    "    cax.set_ylim(cax.get_ylim()[0], isolation_threshold)\n",
    "for c, w, l in zip(\n",
    "    [\"r\", \"k\"], [non_isolated_spots, isolated_spots], [\"non-isolated\", \"isolated\"]\n",
    "):\n",
    "    v = w[\n",
    "        (w.x > extent[1][0])\n",
    "        & (w.x < extent[1][1])\n",
    "        & (w.y > extent[0][0])\n",
    "        & (w.y < extent[0][1])\n",
    "    ]\n",
    "    axes[1].scatter(\n",
    "        v.x - extent[1][0], v.y - extent[0][0], s=2, c=c, marker=\"+\", label=l\n",
    "    )\n",
    "axes[1].legend(\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.0, 0.0),\n",
    ")\n",
    "axes[1].set_title(\"Annulus projection\")\n",
    "\n",
    "# plot annulus values only where spots are\n",
    "img = np.zeros_like(annulus_part) + np.nan\n",
    "values = annulus_image[spots[\"y\"], spots[\"x\"]]\n",
    "valid_values = annulus_image[valid_spots[\"y\"], valid_spots[\"x\"]]\n",
    "for i, spot in valid_spots.iterrows():\n",
    "    px = int(spot.x - extent[1][0])\n",
    "    py = int(spot.y - extent[0][0])\n",
    "    img[py, px] = annulus_part[py, px]\n",
    "if len(valid_values) > 0:\n",
    "    vmin, vmax = valid_values.min(), valid_values.max()\n",
    "else:\n",
    "    print(\"No valid values found\")\n",
    "    vmin, vmax = 0, 1\n",
    "sc = axes[2].scatter(\n",
    "    valid_spots.x - extent[1][0],\n",
    "    valid_spots.y - extent[0][0],\n",
    "    s=2,\n",
    "    c=valid_values,\n",
    "    marker=\"x\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "axes[2].set_title(\"Annulus projection, spot values\")\n",
    "plot_matrix_with_colorbar(img, axes[2], vmin=vmin, vmax=vmax)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract spots\n",
    "\n",
    "Now that we have detected isolated spots, we can extract the fluorescence of each spot.\n",
    "This is done with a given radius around the spot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots = detect_isolated_spots(\n",
    "    reference,\n",
    "    detection_threshold=detection_threshold,\n",
    "    isolation_threshold=isolation_threshold,\n",
    ")\n",
    "\n",
    "iss.call.extract_spots(spots, stack, ops[\"spot_extraction_radius\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spots in the part of reference image and show the extraction radius\n",
    "from skimage.morphology import disk\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "axes = [plt.subplot2grid(fig=fig, shape=(2, 2), loc=(0, i)) for i in range(2)]\n",
    "w = 50\n",
    "smallext = [\n",
    "    [center[1] - w, center[1] + w],\n",
    "    [center[0] - w, center[0] + w],\n",
    "]\n",
    "\n",
    "valid_spots = spots[\n",
    "    (spots.x > smallext[1][0])\n",
    "    & (spots.x < smallext[1][1])\n",
    "    & (spots.y > smallext[0][0])\n",
    "    & (spots.y < smallext[0][1])\n",
    "]\n",
    "\n",
    "ref_part = reference[slice(*smallext[0]), slice(*smallext[1])]\n",
    "\n",
    "plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[0],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    ")\n",
    "axes[0].set_title(\"Standard deviation projection\")\n",
    "axes[0].scatter(\n",
    "    valid_spots.x - smallext[1][0],\n",
    "    valid_spots.y - smallext[0][0],\n",
    "    s=2,\n",
    "    c=\"r\",\n",
    "    marker=\"x\",\n",
    ")\n",
    "\n",
    "\n",
    "spot_footprint = disk(ops[\"spot_extraction_radius\"])\n",
    "drr, dcc = np.where(spot_footprint)\n",
    "drr -= spot_footprint.shape[0] // 2\n",
    "dcc -= spot_footprint.shape[1] // 2\n",
    "\n",
    "img = np.zeros_like(ref_part) + np.nan\n",
    "traces = []\n",
    "\n",
    "for i, spot in spots.iterrows():\n",
    "    if (\n",
    "        spot.x <= smallext[1][0]\n",
    "        or spot.x >= smallext[1][1]\n",
    "        or spot.y <= smallext[0][0]\n",
    "        or spot.y >= smallext[0][1]\n",
    "    ):\n",
    "        continue\n",
    "    traces.append(spot.trace)\n",
    "    rr = np.clip(drr + spot[\"y\"] - smallext[0][0], 0, img.shape[0] - 1)\n",
    "    cc = np.clip(dcc + spot[\"x\"] - smallext[1][0], 0, img.shape[1] - 1)\n",
    "    img[rr, cc] = ref_part[rr, cc]\n",
    "cmap = plt.cm.viridis\n",
    "cmap.set_bad(\"black\", 1)\n",
    "plot_matrix_with_colorbar(\n",
    "    img,\n",
    "    axes[1],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    "    cmap=cmap,\n",
    "    interpolation=\"none\",\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Extracted pixels\")\n",
    "print(f\"Spot extraction radius: {ops['spot_extraction_radius']}.\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "axes_t = plt.subplot2grid(fig=fig, shape=(2, 1), loc=(1, 0))\n",
    "traces = np.stack(traces, axis=2)\n",
    "traces = np.moveaxis(traces, [0, 1], [1, 2])\n",
    "rgb_trace = iss.vis.to_rgb(\n",
    "    traces,\n",
    "    colors=[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 1.0], [0.0, 1.0, 1.0]],\n",
    "    vmin=[0] * 4,\n",
    "    vmax=[traces.max()] * 4,\n",
    ")\n",
    "axes_t.imshow(rgb_trace, aspect=\"auto\", interpolation=\"None\")\n",
    "axes_t.set_xlabel(\"Round\")\n",
    "axes_t.set_ylabel(\"Rolonie\")\n",
    "axes_t.set_title(\"Extracted fluorescence\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on all tiles\n",
    "\n",
    "We will now load all the spots of the reference tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.pipeline.sequencing import get_reference_spots\n",
    "\n",
    "all_spots, norm_shifts = get_reference_spots(data_path, prefix=short_pref)\n",
    "print(f\"Found {len(all_spots)} reference spots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster one round\n",
    "\n",
    "We will run the clustering part on one single round to see how to set score thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iround = 5\n",
    "score_thresh = ops[f\"{short_pref}_cluster_score_thresh\"]\n",
    "print(f\"Filtering cluster with score below {score_thresh}.\")\n",
    "spot_colors = np.stack(spots[\"trace\"], axis=2)  # round x channels x spots\n",
    "spot_round = spot_colors[iround, :, :].T\n",
    "\n",
    "# now we will run scale_k_means on the spot_round. Here we do it manually to\n",
    "# access the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise scaled k-means\n",
    "nch = spot_round.shape[1]\n",
    "initial_cluster_mean = np.array(ops[\"initial_cluster_means\"])\n",
    "\n",
    "x = spot_round\n",
    "norm_cluster_mean = initial_cluster_mean / np.linalg.norm(\n",
    "    initial_cluster_mean, axis=1\n",
    ").reshape(-1, 1)\n",
    "x_norm = x / np.linalg.norm(x, axis=1).reshape(-1, 1)\n",
    "n_clusters = initial_cluster_mean.shape[0]\n",
    "n_points, n_dims = x.shape\n",
    "cluster_ind = (\n",
    "    np.ones(x.shape[0], dtype=int) * -2\n",
    ")  # set all to -2 so won't end on first iteration\n",
    "cluster_eig_val = np.zeros(n_clusters)\n",
    "\n",
    "if len(np.array([score_thresh]).flatten()) == 1:\n",
    "    # if single threshold, set the same for each cluster\n",
    "    score_thresh = np.ones(n_clusters) * score_thresh\n",
    "elif isinstance(score_thresh, list):\n",
    "    score_thresh = np.array(score_thresh)\n",
    "    assert len(score_thresh) == n_clusters, \"score_thresh must be length n_clusters\"\n",
    "# and run the first iteration\n",
    "score = x_norm @ norm_cluster_mean.transpose()\n",
    "cluster_ind = np.argmax(score, axis=1)  # find best cluster for each point\n",
    "top_score = score[np.arange(n_points), cluster_ind]\n",
    "top_score[np.where(np.isnan(top_score))[0]] = (\n",
    "    score_thresh.min() - 1\n",
    ")  # don't include nan values\n",
    "plot_max = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 2))\n",
    "mini = np.min(top_score)\n",
    "for i in range(n_clusters):\n",
    "    scores = top_score[cluster_ind == i]\n",
    "    kwargs = dict(\n",
    "        histtype=\"stepfilled\",\n",
    "        alpha=0.5,\n",
    "        label=f\"Cluster {i}\",\n",
    "        bins=np.arange(mini, 1.1, 0.01),\n",
    "        cumulative=False,\n",
    "    )\n",
    "    ax.hist(\n",
    "        scores,\n",
    "        **kwargs,\n",
    "        density=True,\n",
    "    )\n",
    "    if plot_max:\n",
    "        ax.axvline(\n",
    "            scores.max(),\n",
    "            ymin=0,\n",
    "            ymax=0.4,\n",
    "            color=f\"C{i}\",\n",
    "        )\n",
    "for i, th in enumerate(score_thresh):\n",
    "    ax.axvline(\n",
    "        th, ymin=0.6, ymax=1, color=f\"C{i}\", ls=\"--\", label=f\"Threshold {i} - {th}\"\n",
    "    )\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlim([0, 1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cluster means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresh = ops[f\"{short_pref}_cluster_score_thresh\"]\n",
    "print(f\"Using {score_thresh} as the score threshold.\")\n",
    "\n",
    "# badin = np.eye(4)\n",
    "cluster_means, spot_colors, cluster_inds = iss.call.call.get_cluster_means(\n",
    "    all_spots,\n",
    "    score_thresh=0.9,\n",
    "    initial_cluster_mean=np.array(ops[\"initial_cluster_means\"]),\n",
    ")\n",
    "nclusters = cluster_means[0].shape[0]  # maybe it's [1]?\n",
    "nrounds = len(cluster_means)\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1, ncols=nclusters, facecolor=\"w\", label=\"cluster_means\", figsize=(8, 2)\n",
    ")\n",
    "for icluster in range(nclusters):\n",
    "    plt.sca(ax[icluster])\n",
    "    plt.imshow(np.stack(cluster_means, axis=2)[icluster, :, :])\n",
    "    plt.xlabel(\"rounds\")\n",
    "    plt.ylabel(\"channels\")\n",
    "    plt.xticks(np.arange(nrounds), np.arange(1, nrounds + 1, dtype=int))\n",
    "    plt.yticks(np.arange(nch), np.arange(nch, dtype=int))\n",
    "    plt.title(f\"Cluster {icluster+1}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fact = np.load(iss.io.get_processed_path(data_path) / f\"correction_{prefix}.npz\")\n",
    "pixel_dist = norm_fact[\"pixel_dist\"]\n",
    "norm_factors_raw = norm_fact[\"norm_factors_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(4):\n",
    "    plt.plot(norm_factors_raw[channel], \"-o\", label=f\"Channel {channel}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Normalization factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ops[\"initial_cluster_means\"])\n",
    "plt.xticks(np.arange(4))\n",
    "plt.yticks(np.arange(4))\n",
    "plt.title(\"Initial cross-talk matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHannel correction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.image import compute_distribution, filter_stack\n",
    "from iss_preprocess.io.load import load_ops, load_sequencing_rounds\n",
    "\n",
    "nrounds = None\n",
    "\n",
    "ops = load_ops(data_path)\n",
    "nch = len(ops[\"camera_order\"])\n",
    "if nrounds is None:\n",
    "    nrounds = ops[f\"{prefix.split('_')[0]}_rounds\"]\n",
    "\n",
    "max_val = 65535\n",
    "pixel_dist = np.zeros((max_val + 1, nch, nrounds))\n",
    "if prefix == \"genes_round\":\n",
    "    projection = ops[\"genes_projection\"]\n",
    "elif prefix == \"barcode_round\":\n",
    "    projection = ops[\"barcode_projection\"]\n",
    "else:\n",
    "    raise ValueError(\"prefix must be 'genes_round' or 'barcode_round'\")\n",
    "corr_tiles = ops.get(\"correction_tiles\", None)\n",
    "if corr_tiles is None:\n",
    "    print(\"No correction tiles specified - using ref tiles\")\n",
    "    corr_tiles = ops[f\"{prefix.split('_')[0]}_ref_tiles\"]\n",
    "    assert corr_tiles is not None, \"No ref tiles specified\"\n",
    "\n",
    "for tile in corr_tiles:\n",
    "    print(f\"counting pixel values for roi {tile[0]}, tile {tile[1]}, {tile[2]}\")\n",
    "    try:\n",
    "        stack = load_sequencing_rounds(\n",
    "            data_path, tile, suffix=projection, prefix=prefix, nrounds=nrounds\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Tile {tile} not found. Is ops['correction_tiles'] correct?\"\n",
    "        )\n",
    "    stack = filter_stack(\n",
    "        stack,\n",
    "        r1=ops[\"filter_r\"][0],\n",
    "        r2=ops[\"filter_r\"][1],\n",
    "    )\n",
    "    stack[stack < 0] = 0\n",
    "    for iround in range(nrounds):\n",
    "        pixel_dist[:, :, iround] += compute_distribution(\n",
    "            stack[:, :, :, iround], max_value=max_val\n",
    "        )\n",
    "\n",
    "cumulative_pixel_dist = np.cumsum(pixel_dist, axis=0)\n",
    "cumulative_pixel_dist = cumulative_pixel_dist / cumulative_pixel_dist[-1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(pixel_dist[:500, 0, :]), aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_factors_raw = np.zeros((nch, nrounds))\n",
    "for iround in range(nrounds):\n",
    "    for ich in range(nch):\n",
    "        norm_factors_raw[ich, iround] = np.argmax(\n",
    "            cumulative_pixel_dist[:, ich, iround] > ops[\"correction_quantile\"]\n",
    "        )\n",
    "norm_factors_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops[\"correction_quantile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get color on the viridis colormap\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 7))\n",
    "for iround in range(7):\n",
    "    plt.plot(\n",
    "        np.arange(500),\n",
    "        cumulative_pixel_dist[:500, 0, iround],\n",
    "        label=f\"Round {iround}\",\n",
    "        color=colors[iround],\n",
    "    )\n",
    "    plt.scatter(\n",
    "        norm_factors_raw[0, iround],\n",
    "        cumulative_pixel_dist[int(norm_factors_raw[0, iround]), 0, iround],\n",
    "        color=colors[iround],\n",
    "    )\n",
    "plt.legend()\n",
    "plt.ylim(0.99, 1)\n",
    "plt.xlabel(\"Pixel Index\")\n",
    "plt.ylabel(\"Cumulative Pixel Dist\")\n",
    "plt.title(\"Cumulative Pixel Distribution for Each Round\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(7), norm_factors_raw.T, \"-o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "x_ch = np.repeat(np.arange(nch)[:, np.newaxis], nrounds, axis=1)\n",
    "x_round = np.repeat(np.arange(nrounds)[np.newaxis, :], nch, axis=0)\n",
    "channels_encoding = (\n",
    "    OneHotEncoder().fit_transform(x_ch.flatten()[:, np.newaxis]).todense()\n",
    ")\n",
    "x = np.asarray(np.hstack((x_round.flatten()[:, np.newaxis], channels_encoding)))\n",
    "\n",
    "mdl = LinearRegression(fit_intercept=False).fit(\n",
    "    x, np.log(norm_factors_raw.flatten()[:, np.newaxis])\n",
    ")\n",
    "norm_factors_fit = np.exp(mdl.predict(x))\n",
    "norm_factors_fit = np.reshape(norm_factors_fit, norm_factors_raw.shape)\n",
    "\n",
    "\n",
    "for channel in range(4):\n",
    "    plt.plot(\n",
    "        norm_factors_raw[channel], \"-o\", label=f\"Channel {channel}\", color=f\"C{channel}\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        norm_factors_fit[channel],\n",
    "        \"-o\",\n",
    "        label=f\"Channel {channel} Fit\",\n",
    "        color=f\"C{channel}\",\n",
    "        linestyle=\"--\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
