{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select bleedthrough parameters\n",
    "\n",
    "To set up base calling, we need to create bleed-through matrices. This is done by \n",
    "selecting a threshold for spot detection and one for filtering isolated spots. This \n",
    "notebook will help you select the best threshold for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import iss_preprocess as iss\n",
    "\n",
    "data_path = \"becalia_rabies_barseq/BRAC8498.3e/chamber_08\"\n",
    "prefix = \"barcode_round\"\n",
    "ref_tile_index = 0  # which of the reference tiles do we want to use for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = iss.io.load.load_ops(data_path)\n",
    "short_pref = prefix.split(\"_\")[0]\n",
    "ref_tiles = ops[f\"{short_pref}_ref_tiles\"]\n",
    "print(f\"{len(ref_tiles)} reference tiles found. Using {ref_tile_index}.\")\n",
    "ref_tile = ref_tiles[ref_tile_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading registered data for {ref_tile}\")\n",
    "stack, _ = iss.pipeline.load_and_register_sequencing_tile(\n",
    "    data_path,\n",
    "    ref_tile,\n",
    "    filter_r=ops[\"filter_r\"],\n",
    "    prefix=prefix,\n",
    "    suffix=ops[f\"{short_pref}_projection\"],\n",
    "    nrounds=ops[f\"{prefix}s\"],\n",
    "    correct_channels=ops[f\"{short_pref}_correct_channels\"],\n",
    "    corrected_shifts=ops[\"corrected_shifts\"],\n",
    "    correct_illumination=False,\n",
    ")\n",
    "stack = stack[:, :, np.argsort(ops[\"camera_order\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making reference image using STD\")\n",
    "reference = np.std(stack, axis=(2, 3))\n",
    "reference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot detection\n",
    "\n",
    "First step is to detect some spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.segment.spots import detect_spots\n",
    "\n",
    "ops = iss.io.load.load_ops(data_path)\n",
    "detection_threshold = (ops[f\"{short_pref}_detection_threshold\"],)\n",
    "print(detection_threshold)\n",
    "spots = detect_spots(reference, threshold=detection_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the place with the highest density of spots, just for plotting\n",
    "x, y = spots[\"x\"].values, spots[\"y\"].values\n",
    "# Create a grid of potential disk centers\n",
    "x_grid, y_grid = np.meshgrid(\n",
    "    np.arange(200, stack.shape[1] - 200, 25),\n",
    "    np.arange(200, stack.shape[0] - 200, 25),\n",
    ")\n",
    "# Compute the Euclidean distance from each spot to each potential center\n",
    "distances = np.sqrt((x[:, None, None] - x_grid) ** 2 + (y[:, None, None] - y_grid) ** 2)\n",
    "# Count the number of spots within a 100px radius for each potential center\n",
    "counts = np.sum(distances <= 50, axis=0)\n",
    "center = np.unravel_index(counts.argmax(), counts.shape)\n",
    "center = (x_grid[center], y_grid[center])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.vis import round_to_rgb, plot_matrix_with_colorbar\n",
    "\n",
    "w = 200\n",
    "extent = [[center[1] - w, center[1] + w], [center[0] - w, center[0] + w]]\n",
    "\n",
    "valid_spots = spots[\n",
    "    (spots.x > extent[1][0])\n",
    "    & (spots.x < extent[1][1])\n",
    "    & (spots.y > extent[0][0])\n",
    "    & (spots.y < extent[0][1])\n",
    "]\n",
    "\n",
    "rgb = round_to_rgb(\n",
    "    stack,\n",
    "    1,\n",
    "    extent=extent,\n",
    "    channel_colors=([1, 0, 0], [0, 1, 0], [1, 0, 1], [0, 1, 1]),\n",
    "    vmax=np.percentile(stack[..., 0], 99.99, axis=(0, 1)),\n",
    "    vmin=np.percentile(stack[..., 0], 0.2, axis=(0, 1)),\n",
    ")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# make a colorbar and hide it to have axis the same size\n",
    "cax, cb = plot_matrix_with_colorbar(rgb, axes[0])\n",
    "cax.clear()\n",
    "cax.axis(\"off\")\n",
    "axes[0].set_title(\"Raw data, round 1\")\n",
    "ref_part = reference[slice(*extent[0]), slice(*extent[1])]\n",
    "cax, cb = plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[1],\n",
    "    cmap=\"viridis\",\n",
    "    vmax=np.percentile(reference, 99.999),\n",
    "    vmin=np.percentile(reference, 0.2),\n",
    ")\n",
    "axes[1].contour(ref_part, levels=[detection_threshold], colors=\"r\", linewidths=0.5)\n",
    "cax.axhline(detection_threshold, color=\"r\", lw=2)\n",
    "axes[1].set_title(\"Standard deviation projection\")\n",
    "for ax in axes:\n",
    "    ax.scatter(\n",
    "        valid_spots.x - extent[1][0],\n",
    "        valid_spots.y - extent[0][0],\n",
    "        s=2,\n",
    "        c=\"k\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select isolated spots\n",
    "\n",
    "We keep only spots with a minimum distance to the next spot. This is done by mesuring\n",
    "the fluorescence in an annulus around each spot and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iss_preprocess.segment import detect_isolated_spots\n",
    "from iss_preprocess.coppafish import annulus\n",
    "\n",
    "ops = iss.io.load.load_ops(data_path)\n",
    "isolation_threshold = ops[f\"{short_pref}_isolation_threshold\"]\n",
    "print(isolation_threshold)\n",
    "annulus_r = (3, 7)\n",
    "strel = annulus(annulus_r[0], annulus_r[1])\n",
    "strel = strel / np.sum(strel)\n",
    "annulus_image = scipy.ndimage.correlate(reference, strel)\n",
    "isolated = annulus_image[spots[\"y\"], spots[\"x\"]] < isolation_threshold\n",
    "isolated_spots = spots[isolated]\n",
    "non_isolated_spots = spots[~isolated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annulus_part = annulus_image[slice(*extent[0]), slice(*extent[1])]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[0],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    ")\n",
    "axes[0].set_title(\"Standard deviation projection\")\n",
    "\n",
    "cax, cb = plot_matrix_with_colorbar(\n",
    "    annulus_part,\n",
    "    axes[1],\n",
    "    vmax=np.percentile(annulus_part, 99.999),\n",
    "    vmin=np.percentile(annulus_part, 0.05),\n",
    ")\n",
    "print(isolation_threshold)\n",
    "cax.axhline(isolation_threshold, color=\"r\", lw=2)\n",
    "if isolation_threshold < cax.get_ylim()[0]:\n",
    "    cax.set_ylim(isolation_threshold, cax.get_ylim()[1])\n",
    "if isolation_threshold > cax.get_ylim()[1]:\n",
    "    cax.set_ylim(cax.get_ylim()[0], isolation_threshold)\n",
    "for c, w, l in zip(\n",
    "    [\"r\", \"k\"], [non_isolated_spots, isolated_spots], [\"non-isolated\", \"isolated\"]\n",
    "):\n",
    "    v = w[\n",
    "        (w.x > extent[1][0])\n",
    "        & (w.x < extent[1][1])\n",
    "        & (w.y > extent[0][0])\n",
    "        & (w.y < extent[0][1])\n",
    "    ]\n",
    "    axes[1].scatter(\n",
    "        v.x - extent[1][0], v.y - extent[0][0], s=2, c=c, marker=\"+\", label=l\n",
    "    )\n",
    "axes[1].legend(\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.0, 0.0),\n",
    ")\n",
    "axes[1].set_title(\"Annulus projection\")\n",
    "\n",
    "# plot annulus values only where spots are\n",
    "img = np.zeros_like(annulus_part) + np.nan\n",
    "values = annulus_image[spots[\"y\"], spots[\"x\"]]\n",
    "valid_values = annulus_image[valid_spots[\"y\"], valid_spots[\"x\"]]\n",
    "for i, spot in valid_spots.iterrows():\n",
    "    px = int(spot.x - extent[1][0])\n",
    "    py = int(spot.y - extent[0][0])\n",
    "    img[py, px] = annulus_part[py, px]\n",
    "vmin, vmax = valid_values.min(), valid_values.max()\n",
    "sc = axes[2].scatter(\n",
    "    valid_spots.x - extent[1][0],\n",
    "    valid_spots.y - extent[0][0],\n",
    "    s=2,\n",
    "    c=valid_values,\n",
    "    marker=\"x\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "axes[2].set_title(\"Annulus projection, spot values\")\n",
    "plot_matrix_with_colorbar(img, axes[2], vmin=vmin, vmax=vmax)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract spots\n",
    "\n",
    "Now that we have detected isolated spots, we can extract the fluorescence of each spot.\n",
    "This is done with a given radius around the spot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots = detect_isolated_spots(\n",
    "    reference,\n",
    "    detection_threshold=detection_threshold,\n",
    "    isolation_threshold=isolation_threshold,\n",
    ")\n",
    "\n",
    "iss.call.extract_spots(spots, stack, ops[\"spot_extraction_radius\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spots in the part of reference image and show the extraction radius\n",
    "from skimage.morphology import disk\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "axes = [plt.subplot2grid(fig=fig, shape=(2, 2), loc=(0, i)) for i in range(2)]\n",
    "w = 50\n",
    "smallext = [\n",
    "    [center[1] - w, center[1] + w],\n",
    "    [center[0] - w, center[0] + w],\n",
    "]\n",
    "\n",
    "valid_spots = spots[\n",
    "    (spots.x > smallext[1][0])\n",
    "    & (spots.x < smallext[1][1])\n",
    "    & (spots.y > smallext[0][0])\n",
    "    & (spots.y < smallext[0][1])\n",
    "]\n",
    "\n",
    "ref_part = reference[slice(*smallext[0]), slice(*smallext[1])]\n",
    "\n",
    "plot_matrix_with_colorbar(\n",
    "    ref_part,\n",
    "    axes[0],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    ")\n",
    "axes[0].set_title(\"Standard deviation projection\")\n",
    "axes[0].scatter(\n",
    "    valid_spots.x - smallext[1][0],\n",
    "    valid_spots.y - smallext[0][0],\n",
    "    s=2,\n",
    "    c=\"r\",\n",
    "    marker=\"x\",\n",
    ")\n",
    "\n",
    "\n",
    "spot_footprint = disk(ops[\"spot_extraction_radius\"])\n",
    "drr, dcc = np.where(spot_footprint)\n",
    "drr -= spot_footprint.shape[0] // 2\n",
    "dcc -= spot_footprint.shape[1] // 2\n",
    "\n",
    "img = np.zeros_like(ref_part) + np.nan\n",
    "traces = []\n",
    "\n",
    "for i, spot in spots.iterrows():\n",
    "    if (\n",
    "        spot.x <= smallext[1][0]\n",
    "        or spot.x >= smallext[1][1]\n",
    "        or spot.y <= smallext[0][0]\n",
    "        or spot.y >= smallext[0][1]\n",
    "    ):\n",
    "        continue\n",
    "    traces.append(spot.trace)\n",
    "    rr = np.clip(drr + spot[\"y\"] - smallext[0][0], 0, img.shape[0] - 1)\n",
    "    cc = np.clip(dcc + spot[\"x\"] - smallext[1][0], 0, img.shape[1] - 1)\n",
    "    img[rr, cc] = ref_part[rr, cc]\n",
    "cmap = plt.cm.viridis\n",
    "cmap.set_bad(\"black\", 1)\n",
    "plot_matrix_with_colorbar(\n",
    "    img,\n",
    "    axes[1],\n",
    "    vmax=np.percentile(ref_part, 99.999),\n",
    "    vmin=np.percentile(ref_part, 0.2),\n",
    "    cmap=cmap,\n",
    "    interpolation=\"none\",\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Extracted pixels\")\n",
    "print(f\"Spot extraction radius: {ops['spot_extraction_radius']}.\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "axes_t = plt.subplot2grid(fig=fig, shape=(2, 1), loc=(1, 0))\n",
    "traces = np.stack(traces, axis=2)\n",
    "traces = np.moveaxis(traces, [0, 1], [1, 2])\n",
    "rgb_trace = iss.vis.to_rgb(\n",
    "    traces,\n",
    "    colors=[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 1.0], [0.0, 1.0, 1.0]],\n",
    "    vmin=[0] * 4,\n",
    "    vmax=[traces.max()] * 4,\n",
    ")\n",
    "axes_t.imshow(rgb_trace, aspect=\"auto\", interpolation=\"None\")\n",
    "axes_t.set_xlabel(\"Round\")\n",
    "axes_t.set_ylabel(\"Rolonie\")\n",
    "axes_t.set_title(\"Extracted fluorescence\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on all tiles\n",
    "\n",
    "We will now load all the spots of the reference tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spots, norm_shifts = iss.pipeline.sequencing.get_reference_spots(\n",
    "    data_path, prefix=short_pref\n",
    ")\n",
    "print(f\"Found {len(all_spots)} reference spots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster one round\n",
    "\n",
    "We will run the clustering part on one single round to see how to set score thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iround = 12\n",
    "score_thresh = ops[f\"{short_pref}_cluster_score_thresh\"]\n",
    "print(f\"Filtering cluster with score below {score_thresh}.\")\n",
    "spot_colors = np.stack(spots[\"trace\"], axis=2)  # round x channels x spots\n",
    "spot_round = spot_colors[iround, :, :].T\n",
    "\n",
    "# now we will run scale_k_means on the spot_round. Here we do it manually to\n",
    "# access the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise scaled k-means\n",
    "nch = spot_round.shape[1]\n",
    "initial_cluster_mean = np.array(ops[\"initial_cluster_means\"])\n",
    "\n",
    "x = spot_round\n",
    "norm_cluster_mean = initial_cluster_mean / np.linalg.norm(\n",
    "    initial_cluster_mean, axis=1\n",
    ").reshape(-1, 1)\n",
    "x_norm = x / np.linalg.norm(x, axis=1).reshape(-1, 1)\n",
    "n_clusters = initial_cluster_mean.shape[0]\n",
    "n_points, n_dims = x.shape\n",
    "cluster_ind = (\n",
    "    np.ones(x.shape[0], dtype=int) * -2\n",
    ")  # set all to -2 so won't end on first iteration\n",
    "cluster_eig_val = np.zeros(n_clusters)\n",
    "\n",
    "if len(np.array([score_thresh]).flatten()) == 1:\n",
    "    # if single threshold, set the same for each cluster\n",
    "    score_thresh = np.ones(n_clusters) * score_thresh\n",
    "elif isinstance(score_thresh, list):\n",
    "    score_thresh = np.array(score_thresh)\n",
    "    assert len(score_thresh) == n_clusters, \"score_thresh must be length n_clusters\"\n",
    "# and run the first iteration\n",
    "score = x_norm @ norm_cluster_mean.transpose()\n",
    "cluster_ind = np.argmax(score, axis=1)  # find best cluster for each point\n",
    "top_score = score[np.arange(n_points), cluster_ind]\n",
    "top_score[np.where(np.isnan(top_score))[0]] = (\n",
    "    score_thresh.min() - 1\n",
    ")  # don't include nan values\n",
    "plot_max = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 2))\n",
    "mini = np.min(top_score)\n",
    "for i in range(n_clusters):\n",
    "    scores = top_score[cluster_ind == i]\n",
    "    kwargs = dict(\n",
    "        histtype=\"stepfilled\",\n",
    "        alpha=0.5,\n",
    "        label=f\"Cluster {i}\",\n",
    "        bins=np.arange(mini, 1.1, 0.01),\n",
    "        cumulative=False,\n",
    "    )\n",
    "    ax.hist(\n",
    "        scores,\n",
    "        **kwargs,\n",
    "        density=True,\n",
    "    )\n",
    "    if plot_max:\n",
    "        ax.axvline(\n",
    "            scores.max(),\n",
    "            ymin=0,\n",
    "            ymax=0.4,\n",
    "            color=f\"C{i}\",\n",
    "        )\n",
    "for i, th in enumerate(score_thresh):\n",
    "    ax.axvline(th, ymin=0.6, ymax=1, color=f\"C{i}\", ls=\"--\", label=f\"Threshold {i}\")\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlim([0.5, 1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cluster means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresh = ops[f\"{short_pref}_cluster_score_thresh\"]\n",
    "print(f\"Using {score_thresh} as the score threshold.\")\n",
    "\n",
    "# badin = np.eye(4)\n",
    "cluster_means, spot_colors, cluster_inds = iss.call.call.get_cluster_means(\n",
    "    all_spots, score_thresh=0.9, initial_cluster_mean=np.array(ops[\"initial_cluster_means\"])\n",
    ")\n",
    "nclusters = cluster_means[0].shape[0]  # maybe it's [1]?\n",
    "nrounds = len(cluster_means)\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1, ncols=nclusters, facecolor=\"w\", label=\"cluster_means\", figsize=(8, 2)\n",
    ")\n",
    "for icluster in range(nclusters):\n",
    "    plt.sca(ax[icluster])\n",
    "    plt.imshow(np.stack(cluster_means, axis=2)[icluster, :, :])\n",
    "    plt.xlabel(\"rounds\")\n",
    "    plt.ylabel(\"channels\")\n",
    "    plt.xticks(np.arange(nrounds), np.arange(1, nrounds + 1, dtype=int))\n",
    "    plt.yticks(np.arange(nch), np.arange(nch, dtype=int))\n",
    "    plt.title(f\"Cluster {icluster+1}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fact = np.load(\n",
    "    iss.io.get_processed_path(data_path) / f\"correction_{prefix}.npz\"\n",
    ")\n",
    "pixel_dist = norm_fact[\"pixel_dist\"]\n",
    "norm_factors_raw = norm_fact[\"norm_factors_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(4):\n",
    "    plt.plot(norm_factors_raw[channel], \"-o\", label=f\"Channel {channel}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Normalization factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ops[\"initial_cluster_means\"])\n",
    "plt.xticks(np.arange(4))\n",
    "plt.yticks(np.arange(4))\n",
    "plt.title(\"Initial cross-talk matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
